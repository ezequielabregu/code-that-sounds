# Sonification

In this chapter, we will explore the concept of sonification, its applications, and how it can be implemented using Pure Data (Pd). We will also discuss the importance of understanding data types and classifications in the context of sonification.

## Introduction
Imagine hearing the changes in global temperature over the past thousand years. What does a brainwave sound like? How can sound be used to enhance a pilot’s performance in the cockpit? These intriguing questions, among many others, fall within the realm of **auditory display** and **sonification**.

Researchers in Auditory Display explore how the human auditory system can serve as a primary interface channel for communicating and conveying information. The goal of auditory display is to foster a deeper understanding or appreciation of the patterns and structures embedded in data beyond what is visible on the screen. 

Auditory display encompasses all aspects of human-computer interaction systems, including the hardware setup (speakers or headphones), modes of interaction with the display system, and any technical solutions for data collection, processing, and computation needed to generate sound in response to data. 

In contrast, **sonification** is a core technique within auditory display: the process of rendering sound from data and interactions. Unlike voice interfaces or artistic soundscapes, auditory displays have gained increasing attention in recent years and are becoming a standard method alongside visualization for presenting data across diverse contexts.

The international research effort to understand every aspect of auditory display began with the founding of the **International Community for Auditory Display (ICAD)** in 1992. It is fascinating to observe how sonification and auditory display techniques have evolved in the relatively short time since their formal definition, with development accelerating steadily since 2011.

Auditory display and sonification are now employed across a wide range of fields. Applications include chaos theory, biomedicine, interfaces for visually impaired users, data mining, seismology, desktop and mobile computing interaction, among many others. 

Equally diverse is the set of research disciplines required for successful sonification: physics, acoustics, psychoacoustics, perceptual research, sound engineering, and computer science form the core technical foundations. However, psychology, musicology, cognitive science, linguistics, pedagogy, social sciences, and philosophy are also essential for a comprehensive, multifaceted understanding of the description, technical implementation, usage, training, comprehension, acceptance, evaluation, and ergonomics of auditory displays and sonification in particular.

It is clear that in such an interdisciplinary field, a narrow focus on any single discipline risks “seeing the trees but missing the forest.” As with all interdisciplinary research efforts, auditory display and sonification face significant challenges, ranging from differing theoretical orientations across fields to even the very vocabulary used to describe our work. 

Interdisciplinary dialogue is crucial to advancing auditory display and sonification. However, the field must overcome the challenge of developing and employing a shared language that integrates many divergent disciplinary ways of speaking, thinking, and approaching problems. On the other hand, this very challenge often unlocks great creative potential and new ideas, as these varied perspectives can spark innovation and fresh insights.


## Data Types

In the realm of digital data, understanding the nature and classification of data types is essential for their effective processing, storage, and analysis. The table above presents a detailed taxonomy of data types broadly categorized into **Static** and **Stream / Realtime** data, further subdivided into various subtypes. This section will unpack these classifications, elaborating on their characteristics, common formats, and sources.

### Static Data

Static data refers to data that is stored and remains unchanged until explicitly modified. It is typically collected, stored, and then analyzed or processed offline or asynchronously. This type of data is fundamental in many computational tasks, including machine learning, data mining, and archival storage.

#### Structured Data

Structured data is organized in a predefined manner, typically conforming to a schema or model that allows easy querying and manipulation.

**Examples:**

* **Datasets (CSV, XLS):** Tabular data with rows and columns, where each column has a defined datatype (e.g., numeric, string, datetime).
* **Fields:** The basic elements of structured data that have specific data types, such as integers, floating-point numbers, text strings, or timestamps.
* **Classes:** Labels used in supervised learning, often binary (two classes) or multiclass (multiple categories).
* **Images:** Digital images can be structured if stored with metadata or standardized file formats. Examples include compressed formats like JPG and uncompressed formats like BMP.
* **MIDI Files:** Musical Instrument Digital Interface files encode structured note and control information.
* **Audio:** Raw waveforms or extracted descriptors (e.g., Mel-frequency cepstral coefficients - MFCCs, Fourier transforms) represent audio signals in structured formats.
* **Audio Formats:** Common audio file formats such as MP3 (compressed), FLAC (lossless compressed), and WAV (uncompressed).

**Sources:** Data portals (e.g., Kaggle, UCI Machine Learning Repository), social media platforms like Instagram, Reddit, Flickr (for images), and audio repositories.



#### Semi-structured Data

Semi-structured data does not conform to a rigid schema like structured data but still contains tags or markers to separate semantic elements.

**Examples:**

* **Markup Languages:** HTML, XML, JSON, and YAML files are examples of semi-structured data because they contain hierarchical tags and attributes describing the data, but the content may be variable.

**Sources:** Web content, APIs that deliver data in JSON or XML formats.


#### Unstructured Data

Unstructured data lacks a predefined data model or schema. It is the most common form of data generated and can be more challenging to analyze without preprocessing.

**Examples:**

* **Texts:** Documents, emails, articles, or social media posts are typical unstructured data examples.

**Sources:** Document collections, text corpora, email archives.


### Stream / Realtime Data

Stream or realtime data refers to continuous data generated in real-time, often requiring immediate or near-immediate processing. These data types are crucial in applications like live monitoring, interactive systems, and real-time analytics.

**Examples:**

* **Audio Streams:** Continuous audio feeds such as online radio broadcasts.
* **Video Streams:** Live video feeds from CCTV cameras or autonomous vehicles.
* **Sensor Data:** Real-time telemetry or environmental data from IoT devices, Arduino boards, or embedded systems.
* **Live MIDI:** Streaming musical performance data, used in live concerts or interactive installations.
* **OSC (Open Sound Control):** A protocol used for networking sound synthesizers, computers, and other multimedia devices, enabling real-time control.

**Sources:** Online radio platforms, surveillance systems, smart vehicles, embedded IoT devices, live music performance setups.


## Data Classification

The classification of data into **static** and **stream/realtime** reflects fundamentally different operational paradigms in digital systems. Static data often allows batch processing, archival, and complex analysis without stringent timing constraints. In contrast, stream data demands continuous, low-latency processing to support live feedback, monitoring, or interaction.

The **structured / semi-structured / unstructured** distinction highlights the complexity of dealing with data formats:

* **Structured data** is well-suited for traditional databases and straightforward analysis.
* **Semi-structured data** requires flexible parsers and understanding of nested or tagged data.
* **Unstructured data** often necessitates advanced techniques such as natural language processing or computer vision for meaningful extraction.

Understanding these data types and their sources is critical when designing systems for data ingestion, storage, processing, and analysis — especially in fields such as machine learning, multimedia processing, and IoT applications.


+-----------------------+---------------------+------------------------------------------------------------------------+--------------------------------------------+
| Type                  | Subtype             | Examples                                                               | Sources                                    |
+=======================+=====================+========================================================================+============================================+
| Static                | Structured          | - Datasets (CSV, XLS)                                                  | - Data portals                             |
|                       |                     | - Fields: numeric, string, datetime                                    |                                            |
|                       |                     | - Classes: binary, multiclass                                          |                                            |
|                       |                     | - Images (compressed: JPG, uncompressed: BMP)                          | - Instagram, Reddit, Flickr                |
|                       |                     | - MIDI files                                                           |                                            |
|                       |                     | - Audio: raw, descriptors, Fourier                                     | - Audio repositories                       |
|                       |                     | - Audio formats: MP3, FLAC, WAV                                        |                                            |
|                       | Semi-structured     | - Markup languages: HTML, XML, JSON, YAML                              | - Web, APIs                                |
|                       | Unstructured        | - Texts                                                                | - Document collections                     |
+=======================+=====================+========================================================================+============================================+
| Stream / Realtime     | —                   | - Audio streams (e.g. online radio)                                    | - Online radio platforms                   |
|                       |                     | - Video streams (e.g. CCTV, autonomous vehicles)                       | - Surveillance systems, smart vehicles     |
|                       |                     | - Sensor data (e.g. Arduino, real-time telemetry)                      | - IoT devices, embedded systems            |
|                       |                     | - Live MIDI                                                            | - Live performance setups                  |
|                       |                     | - OSC (Open Sound Control)                                             | - Interactive art and media systems        |
+-----------------------+---------------------+------------------------------------------------------------------------+--------------------------------------------+

### References


Gantz, J., & Reinsel, D. (2012). The Digital Universe in 2020: Big Data, Bigger Digital Shadows, and Biggest Growth in the Far East. *IDC iView*.


Marr, B. (2016). Big Data in Practice: How 45 Successful Companies Used Big Data Analytics to Deliver Extraordinary Results. Wiley.

## Sonification as a Creative Framework

Sonification, traditionally defined as the systematic, objective, and reproducible translation of data into sound, finds itself at a dynamic intersection between scientific inquiry and creative expression. While often framed within the methodological rigor of data representation, its deeper potential lies equally in its artistic embodiment—an expressive convergence of logic, perception, and auditory imagination. This duality is vital when considering the use of software in the development of creative code practices for sonification. In its essence, sonification provides a means to explore and interpret data temporally. It transforms static information into dynamic sonic experiences, revealing patterns not just to the analytical mind but to the aesthetic ear. As Gresham-Lancaster [@greshamlancaster2012] argues, the field must extend beyond scientific formalism to embrace a broader spectrum of cultural and musical meaning. 

A foundational concept introduced by Gresham-Lancaster is the distinction between first-order and second-order sonification. First-order sonification typically involves straightforward mapping of data points to sound parameters—e.g., a numerical value controlling oscillator frequency or filter cutoff. This direct translation preserves the integrity of the data but may lack emotional resonance or contextual clarity for listeners unfamiliar with the dataset or mappings. Second-order sonification introduces a higher level of abstraction. Here, data is not merely converted to sound but is used to control compositional structures such as rhythm, harmony, timbre, and formal development. This could manifest through software designs that incorporate statistical analysis of datasets to determine musical motifs or drive stochastic processes that evolve over time. By embedding data within culturally familiar or stylistically resonant frameworks—be it ambient textures, rhythmic patterns, or harmonic progressions allows the sonification to become more legible and emotionally impactful.

A key insight is that listeners inevitably interpret sound within a cultural and stylistic frame. Whether intentional or not, sonification software maps data to sonic outputs will be perceived through the lens of genre conventions—ambient, noise, glitch, minimalism, etc. This reinforces the necessity for designers of sonification systems to consciously engage with aesthetic decisions. Rather than viewing these as distractions from scientific rigor, they should be recognized as essential design variables that determine how well the sonification communicates. For instance, layering the sonified stream within an evolving drone texture or embedding it in rhythmic pulses tied to diurnal cycles may enhance the intelligibility of subtle shifts. These choices, while extramusical, profoundly affect the user's ability to detect and interpret meaningful changes.

The expressive capacity of sonification technics invites an analogy with sculpture, as cited in Xenakis’ conception of raw mathematical outputs as "virtual stones" to be artistically shaped. The creative coder similarly refines the raw outputs of data-driven patches, sculpting auditory forms through iterative experimentation, parameter tuning, and aesthetic discernment. This process reveals sonification not as a deterministic output of data, but as a collaboration between the structure of information and the intuition of the artist-programmer. Moreover, by incorporating techniques such as timbral mapping, adaptive filtering, and data-driven granular synthesis, it becomes a laboratory for crafting sonic experiences that honor both the source data and the listener’s perceptual world. This is particularly effective when the goal is to embed sonification within broader artistic or performative contexts—installations, interactive systems, or generative concerts—where expressivity and audience engagement are critical.

The evolution of sonification within the creative coding domain demands a reconceptualization of what constitutes success in sonification. Beyond reproducibility, the true measure lies in perceptual clarity, aesthetic engagement, and communicative power. As Gresham-Lancaster asserts, the inclusion of musical form, stylistic awareness, and cultural embedding are not luxuries, but necessities for sonification to become a widely adopted and meaningful practice Pure Data, with its flexibility, open-ended structure, and visual coding paradigm, provides an ideal environment to develop and test both first-order and second-order sonification systems. By embracing both scientific precision and artistic insight, Pd-based sonification becomes a model for interdisciplinary practice—where the auditory exploration of data is not just informative but transformative.


## Data Humanism: A Visual Manifesto of Giorgia Lupi

![Humanism of Data](/assets/images/sonification/datahumanism.jpeg)

Data is now recognized as one of the foundational pillars of our economy, and the idea that the world is exponentially enriched with data every day has long ceased to be news.

Big Data is no longer a distant dystopian future; it is a commodity and an intrinsic, iconic feature of our present—alongside dollars, concrete, automobiles, and Helvetica. The ways we relate to data are evolving faster than we realize, and our minds and bodies are naturally adapting to this new hybrid reality built from physical and informational structures. Visual design, with its unique power to reach deep into our subconscious instantly—bypassing language—and its inherent ability to convey vast amounts of structured and unstructured information across cultures, will play an even more central role in this quiet yet inevitable revolution.

Pioneers of data visualization like William Playfair, John Snow, Florence Nightingale, and Charles Joseph Minard were the first to harness and codify this potential in the 18th and 19th centuries. Modern advocates such as Edward Tufte, Ben Shneiderman, Jeffrey Heer, and Alberto Cairo have been instrumental in the field’s renaissance over the past twenty years, supporting the transition of these principles into the world of Big Data. 

Thanks to this renewed interest, an initial wave of data visualization swept across the web, reaching a wider audience beyond the academic circles where it had previously been confined. Unfortunately, this wave was often ridden superficially—used as a linguistic shortcut to cope with the overwhelming nature of Big Data.

“Cool” infographics promised a key to mastering this untamable complexity. When they inevitably failed to deliver on this overly optimistic expectation, we were left with gigabytes of illegible 3D pie charts and cheap, translucent user interfaces cluttered with widgets that even Tony Stark or John Anderton from *Minority Report* would struggle to understand.

In reality, visual design is often applied to data merely as a cosmetic gloss over serious and complicated problems—an attempt to make them appear simpler than they truly are. What made cheap marketing infographics so popular is perhaps their greatest contradiction: the false claim that a few pictograms and large numbers inherently have the power to “simplify complexity.” The phenomena that govern our world are, by definition, complex, multifaceted, and often difficult to grasp. So why would anyone want to dumb them down when making critical decisions or delivering important messages?

Yet, not all is bleak in this sudden craze for data visualization. We are becoming increasingly aware that there remains a considerable gap between the real potential hidden within vast datasets and the superficial images we typically use to represent them. More importantly, we now recognize that the first wave succeeded in familiarizing a broader audience with new visual languages and tools.

Having moved past what we might call the peak of infographics, we are left with a general audience equipped with some of the necessary skills to welcome a second wave of more meaningful, thoughtful visualization.

We are ready to question the impersonality of a purely technical approach to data and begin designing ways to connect numbers with what they truly represent: knowledge, behaviors, and people.

## References{.unnumbered}
