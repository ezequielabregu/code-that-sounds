{
  "hash": "20d023081813e908a6c0599ff7335eb1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Sequencers\"\njupyter: python3\n---\n\n# Sequencers\n\nIn this chapter, we will explore the concept of sequencers and how they can be implemented in Pure Data.\n\n## Arrays and Sequencers\n\nSequencer is a tool for organizing and controlling the playback of `events` in a temporally ordered sequence. This sequence consists of a series of discrete steps, where each step represents a regular time interval and can contain information about event activation or deactivation.\n\nIn addition to controlling musical events such as notes, chords, and percussions, a step sequencer can also manage a variety of other events. This includes parameter changes in virtual instruments or audio/video synthesizers, real-time effect automation, lighting control in live performances or multimedia installations, triggering of samples to create patterns and effect sequences, as well as firing MIDI control events to operate external hardware or software.\n\n| Step  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  |\n|-------|-----|-----|-----|-----|-----|-----|-----|-----|\n| Value | x   | x   | x   | x   | x   | x   | x   | x   |\n| Index | 0   | 1  | 2  | 3  | 4  | 5  | 6  | 7  |\n\n-   Each cell represents a step in the sequencer.\n-   1 to 8 indicate the steps.\n-   Empty cells represent steps without events or notes.\n-   You can fill each cell with notes or events to represent the desired sequence.\n\n### Represent an 8-step sequencer using pseudo code \n\n#### Formulation (pseudo code)\n\n``` default\nData Structures:\n- Define a data structure to represent each step of the sequence (e.g., array, list).\n\nVariables:\n- Define an array to store the MIDI note values for each step.\n- Initialize the sequencer parameters:\n  - CurrentStep = 0\n  - Tempo\n  - NumberOfSteps = 8\n\nAlgorithm:\n1. Initialization:\n   a. Set CurrentStep to 0.\n   b. Ask the user to input the Tempo.\n   c. Set NumberOfSteps to 8.\n\n2. Loop:\n   a. While true:\n      i. Calculate the time duration for each step based on the Tempo.\n      ii. Play the MIDI note corresponding to the CurrentStep.\n      iii. Increment CurrentStep.\n      iv. If CurrentStep exceeds NumberOfSteps, reset it to 0.\n      v. Wait the calculated duration before moving to the next step.\n```\n\n### Pure Data Implementation of the 8-Step Sequencer\n\n![Fig.](/assets/screenshots/sequencers/step-sequencer.png)\n\nThis is a simple step sequencer for MIDI. It uses the `mido` library to send MIDI messages and the `time` library to control the timing of the sequence.\n\nThe script starts by importing the necessary libraries and defining some data structures and initial variables. The `secuencia` list will hold the sequence of notes to be played, and is initially filled with `None` values. The `notas_midi` list contains the MIDI note values for each step in the sequence, representing a C Major scale.\n\nThen, the script initializes some sequencer parameters. The `paso_actual` variable tracks the current step in the sequence, `tempo` sets the tempo in beats per minute, and `num_pasos` stores the total number of steps in the sequence.\n\nThe script opens a virtual MIDI output port using `mido.open_output()`. You may need to change the port name 'IAC Driver Bus 1' depending on your system setup.\n\nThe main part of the script is a `while` loop that continuously plays the sequence. For each step, it calculates the step duration based on the tempo, plays the corresponding MIDI note, increments the current step, and waits for the calculated duration before moving to the next step. If the current step exceeds the number of steps in the sequence, it resets to 0. After each note is played, a `note_off` MIDI message is sent to stop the note.\n\n### Random Step Sequencer Implementation\n\n![Fig.](/assets/screenshots/sequencers/random-step-sequencer.png)\n\nThis Python script is a modified version of the step-by-step MIDI sequencer from the previous example. The main difference lies in how the current step (`paso_actual`) is incremented.\n\nIn the original script, the current step increased sequentially, creating a predictable pattern of notes. In this modified version, the current step is set to a random integer between 0 and 7 (inclusive). This means that the note sequence will be played in a random order, creating a more unpredictable pattern.\n\n## Piano Phase (Steve Reich)\n\n![Fig.](/assets/images/sequencers/piano-phase-animation-1.gif)\n\n[View Piano Phase Score (S. Reich)](./Biblio%20/SteveReich-PianoPhase.pdf)\n\nDesign patterns are abstractions that capture idiomatic tendencies of practices and processes. These\nabstractions are embedded in live coding languages as\nfunctions and syntax, allowing for the reuse of these\npractices in new projects. [@brown2023]\n\n*Piano Phase* is an example of \"music as a gradual process,\" as Reich stated in his essay from 1968.[@reich2002]. In it, Reich described his interest in using processes to generate music, particularly noting how the process is perceived by the listener. (Processes are deterministic: a description of the process can describe an entire whole composition.\\[5\\] In other words, once the basic pattern and the phase process have been defined, the music consists itself.)\n\nReich called the unexpected ways change occurred via the process \"by-products\", formed by the superimposition of patterns. The superimpositions form sub-melodies, often spontaneously due to echo, resonance, dynamics, and tempo, and the general perception of the listener.[@epstein1986]\n\nPiano Phase led to several breakthroughs that would mark Reich's future compositions. The first is the discovery of using simple but flexible harmonic material, which produces remarkable musical results when phasing occurs. The use of 12-note or 12-division patterns in Piano Phase proved to be successful, and Reich would re-use it in Clapping Music and Music for 18 Musicians. Another novelty is the appearance of rhythmic ambiguity during phasing of a basic pattern. The rhythmic perception during phasing can vary considerably, from being very simple (in-phase), to complex and intricate.\n\nThe first section of Piano Phase has been the section studied most by musicologists. A property of the first section of phase cycle is that it is symmetric, which results in identical patterns half-way through the phase cycle.[@epstein1986]\n\n*Piano Phase* can be conceived as an algorithm. Starting with two pianos playing the same sequence of notes at the same speed, one of the pianists begins to gradually accelerate their tempo.\n\nWhen the separation between the notes played by both pianos reaches a fraction of a note's duration, the phase is shifted and the cycle repeats. This process continues endlessly, creating a hypnotic effect of rhythmic phasing that evolves over time as an infinite sequence of iterations.\n\n![Phase Difference](/assets/images/sequencers/piano-phase-animation-2.gif)\n\n### Algorithm Formulation (pseudo code)\n\n``` default\n1. Initialize two pianists with the same note sequence.\n2. Set an initial tempo for both pianists.\n3. Repeat until the desired phase is reached:\n     a. Gradually increase the second pianist's tempo.\n     b. Compare note positions between both pianists.\n     c. When the separation between the notes reaches a fraction of a note’s duration, invert the phase.\n     d. Continue playback.\n4. Repeat the cycle indefinitely to create a continuous and evolving rhythmic phasing effect.\n```\n\n### Piano Phase Implementation in PD \n\n![fig](/assets/screenshots/sequencers/piano-phase.png)\n\n### Patch Overview\n\nThe piano-phase.pd patch implements a minimalist phasing process inspired by Steve Reich’s Piano Phase. It uses two parallel sequencers, each reading from the same melodic sequence but advancing at slightly different rates. This gradual tempo difference causes the two sequences to drift out of phase, creating evolving rhythmic and melodic patterns.\n\n```{mermaid}\nflowchart TD\n    Start([Start/Stop]) --> M1[Clock 1 410ms]\n    Start --> M2[Clock 2 406ms]\n    M1 --> C1[Counter 1]\n    M2 --> C2[Counter 2]\n    C1 --> T1[read sequence]\n    C2 --> T2[read sequence]\n    T1 --> MK1[MIDI noteout]\n    T2 --> MK2[MIDI noteout]\n```\n\n### Sequence Data\n\n`[table sequence 12]`\n\nThe sequence is stored in a table named sequence with 12 MIDI note values:\n\n`64 66 71 73 74 66 64 73 71 66 74 73`\n\nThis pattern is initialized at patch load.\n\n### Step-by-Step Data Flow\n\n**Initialization**\n\n-   The sequence table is filled with 12 MIDI notes.\n-   Two metro objects are set: one at 410 ms (left), one at 406 ms (right).\n-   Both sequencers are started/stopped with a single toggle.\n\n**Playback**\n\n-   Each metro triggers its own counter, which advances from 0 to 11 and wraps around.\n-   The current index is used to read a note from the sequence table.\n-   The note is played via `makenote` and sent to MIDI output.\n-   The current step is visualized with a horizontal radio button (`hradio`).\n\n**Phasing Effect**\n\n-   The right sequencer is slightly faster, so its step index gradually shifts ahead of the left sequencer.\n-   Over time, the two sequences drift out of phase, producing new rhythmic and melodic combinations.\n-   Eventually, the faster sequencer laps the slower one, and the process repeats.\n\n### Key Objects and Their Roles\n\nTwo identical sequences are played in parallel. Slightly different tempos cause the sequences to gradually shift out of phase. Emergent patterns arise from the interaction of the two sequences. Visual feedback helps track the phase relationship. This patch demonstrates how minimalist processes can generate complex musical results through simple, deterministic rules, echoing the core concept of Steve Reich’s Piano Phase.\n\n| Object               | Purpose                                  |\n|----------------------|------------------------------------------|\n| metro                | Sets the timing for each sequencer       |\n| expr int(60000/\\$f1) | Converts BPM to milliseconds             |\n| f, + 1, mod 12       | Advances and wraps the step index        |\n| tabread sequence     | Reads the current note from the sequence |\n| makenote             | Generates MIDI note-on/off with duration |\n| noteout              | Sends MIDI notes to the output device    |\n| hradio               | Visualizes the current step position     |\n| loadbang             | Initializes sequence and metro intervals |\n\n\n## Random Melody Generator\n\nThis chapter provides a step-by-step explanation of the [music-scale-B.pd](/assets/code/sequencers/music-scale-B.pd) Pure Data patch. The patch demonstrates how to generate a melody using a musical scale, store it in an array, and play it back using MIDI.\n\n![Random Melody Generator](/assets/screenshots/sequencers/random_melody.png)\n\n### Patch Overview\n\nThe patch is organized into several functional blocks:\n\n-   **Scale and Melody Generation**\n-   **Melody Storage**\n-   **Playback Control**\n-   **MIDI Output**\n\nBelow is a simplified diagram of the main data flow:\n\n```{mermaid}\nflowchart TD\n    A[Scale Input] --> B[Melody Generation]\n    B --> C[Store in Array]\n    C --> D[Playback Control]\n    D --> E[MIDI Output]\n```\n\n### Scale and Melody Generation\n\n#### Scale Definition\n\nThe patch starts with a message box containing the scale intervals:\n\n`0 2 4 5 7 9 11`\n\nFor example, this represents a major scale in semitones accordding to the following mapping:\n\n::: {style=\"width: 50%;\"}\n| Note    | Interval |\n|---------|----------|\n| C       | `0`      |\n| C# / Db | `1`      |\n| D       | `2`      |\n| D# / Eb | `3`      |\n| E       | `4`      |\n| F       | `5`      |\n| F# / Gb | `6`      |\n| G       | `7`      |\n| G# / Ab | `8`      |\n| A       | `9`      |\n| A# / Bb | `10`     |\n| B       | `11`     |\n:::\n\n \n\nThe scale is appended to a list and processed to determine its length.\n\n#### Random Note Selection\n\nA random number between 0 and 47 is generated (`random 48`), then shifted up by 60 to get a MIDI note in a typical range.\n\nThe note is then mapped to the scale using modulo operations and list indexing.\n\n#### Melody Construction\n\nThe patch uses a loop (`until`, `i`, `+ 1`) to generate a sequence of notes.\n\nEach note is calculated based on the scale and stored in a list.\n\n### Melody Storage\n\nThe generated melody is stored in a Pure Data array called `melody`.\n\nThe array is visualized in the patch for reference.\n\n```{mermaid}\ngraph LR\n    MelodyList -->|tabwrite| MelodyArray\n```\n\n### Playback Control\n\nA `metro` object (metronome) triggers playback at a tempo set by a horizontal slider.\n\nEach bang from the metronome advances an index, which reads the next note from the `melody` array.\n\n### MIDI Output\n\nThe note value is sent to a `makenote` object, which creates a MIDI note with velocity and duration.\n\nThe note is then sent to the `noteout` object, which outputs the MIDI note to your system's MIDI device.\n\n### Step-by-Step Data Flow\n\n1.  **Initialize Scale**: The scale intervals are defined and appended to a list.\n2.  **Generate Melody**: A loop generates random notes mapped to the scale, storing them in the `melody` array.\n3.  **Playback**: A metronome triggers reading from the array, sending notes to MIDI output.\n4.  **Visualization**: The melody array is displayed as a graph in the patch.\n\n### Key Objects and Their Roles\n\n::: {style=\"width: 50%;\"}\n| Object      | Purpose                                   |\n|-------------|-------------------------------------------|\n| `random 48` | Generates random note indices             |\n| `+ 60`      | Shifts notes to a higher MIDI octave      |\n| `mod 12`    | Maps notes to scale degrees               |\n| `list-idx`  | Retrieves scale degree from the list      |\n| `tabwrite`  | Writes notes to the `melody` array        |\n| `metro`     | Controls playback timing                  |\n| `tabread`   | Reads notes from the `melody` array       |\n| `makenote`  | Creates MIDI notes with velocity/duration |\n| `noteout`   | Sends MIDI notes to output                |\n:::\n\n### Diagram: Melody Generation and Playback\n\n```{mermaid}\nflowchart TD\n    S[Scale Message] --> L[list Append]\n    L --> R[random + Offset]\n    R --> M[Modulo/Indexing]\n    M --> A[Melody Array]\n    A --> P[Playback - metro, tabread]\n    P --> MN[makenote]\n    MN --> NO[noteout]\n```\n\n### Summary\n\nThis patch demonstrates how to algorithmically generate a melody using a musical scale, store it, and play it back via MIDI in Pure Data. The modular structure allows for easy experimentation with different scales, lengths, and playback parameters.\n\n\n## The Euclidean Algorithm Generates Traditional Musical Rhythms\n\nGodfried Toussaint (2005)\n\n![Eucliden image](/assets/images/sequencers/euclidian-seq-1.png)\n\n[Link to the original article](https://cgm.cs.mcgill.ca/~godfried/publications/banff.pdf)\n\n\nThe Euclidean rhythm in music was discovered by Godfried Toussaint in 2004 and is described in a 2005 paper *\"The Euclidean Algorithm Generates Traditional Musical Rhythms\"*.[@toussaint2005] The paper presents a method for generating rhythms that are evenly distributed over a given time span, using the Euclidean algorithm. This method is particularly relevant in the context of world music, where such rhythms are often found. The Euclidean algorithm (as presented in *Euclid's Elements*) calculates the greatest common divisor of two given integers. It is shown here that the structure of the Euclidean algorithm can be used to efficiently generate a wide variety of rhythms used as timelines (ostinatos) in sub-Saharan African music in particular, and world music in general. These rhythms, here called *Euclidean rhythms*, have the property that their onset patterns are distributed as evenly as possible. Euclidean rhythms also find application in nuclear physics accelerators and computer science and are closely related to several families of words and sequences of interest in the combinatorics of words, such as Euclidean strings, with which the rhythms are compared.[@toussaint2005]\n\n### Hypothesis\n\nSeveral researchers have observed that rhythms in traditional world music tend to exhibit patterns distributed as regularly or evenly as possible. The hypothesis is that the Euclidean algorithm can be used to generate these rhythms. According to the hypothesis, the Euclidean algorithm can be used to generate rhythms that are evenly distributed over a given time span. This is particularly relevant in the context of world music, where such rhythms are often found. The following is a summary of the main points:\n\n> **Patterns of maximal evenness can be described using the Euclidean algorithm on the greatest common divisor of two integers.**\n\n### Patterns of Maximal Evenness\n\nThe Pattern of Maximal Evenness is a concept used in music theory to create Euclidean rhythms. Euclidean rhythms are rhythmic patterns that evenly distribute beats over a time cycle.\n\nIn essence, the Pattern of Maximal Evenness seeks to **distribute a specific number of beats evenly** within a given time span. This is achieved by dividing the time into equal parts and assigning beats to these divisions uniformly.\n\nExample:\n\nx = beat\n\n· = rest\n\n\\[×· ×· ×· ×· \\] → \\[1 0 1 0 1 0 1 0\\] (8,4) = 4 beats evenly distributed over 8 pulses\n\n\\[×· ·×· ·×·\\] → \\[1 0 0 1 0 0 1 0\\] (8,3) = 3 beats evenly distributed over 8 pulses\n\n### Euclidean Algorithm\n\nOne of the oldest known algorithms, described in *Euclid's Elements* (around 300 BCE) in Proposition 2 of Book VII, now known as the Euclidean algorithm, calculates the greatest common divisor of two given integers.\n\nThe idea is very simple. The smaller number is repeatedly subtracted from the larger until the larger becomes zero or smaller than the smaller one, in which case it becomes the remainder. This remainder is then repeatedly subtracted from the smaller number to obtain a new remainder. This process continues until the remainder is zero.\n\nTo be more precise, consider the numbers 5 and 8 as an example:\n\n-   First, we divide 8 by 5. This gives a quotient of 1 and a remainder of 3.\n-   Then, we divide 5 by 3, which gives a quotient of 1 and a remainder of 2.\n-   Next, we divide 3 by 2, which gives a quotient of 1 and a remainder of 1.\n-   Finally, we divide 2 by 1, which gives a quotient of 2 and a remainder of 0.\n\nThe idea is to keep dividing the previous divisor by the remainder obtained in each step until the remainder is 0. When we reach a remainder of 0, the previous divisor is the greatest common divisor of the two numbers.\n\nIn short, the process can be seen as a sequence of equations:\n\n``` text\n8 = (1)(5) + 3\n5 = (1)(3) + 2\n3 = (1)(2) + 1\n2 = (1)(2) + 0\n```\n\n*Note: 8 = (1)(5) + 3 means that 8 is divided by 5 once, yielding a quotient of 1 and a remainder of 3.*\n\n \n\nIn essence, it involves successive divisions to find the `greatest common divisor` of two positive numbers (GCD from now on).\n\nThe `GCD` of two numbers a and b, assuming a \\> b, is found by first dividing a by b, and obtaining the remainder r.\n\nThe GCD of a and b is the same as that of b and r. When we divide a by b, we obtain a quotient c and a remainder r such that:\n\n`a = c · b + r`\n\n**Examples:**\n\nLet’s compute the GCD of 17 and 7.\n\nSince `17 = 7 · 2 + 3`, then GCD(17, 7) is equal to GCD(7, 3). Again, since 7 = 3 · 2 + 1, then GCD(7, 3) is equal to GCD(3, 1). Here, it is clear that the GCD between 3 and 1 is simply 1. Therefore, the GCD between 17 and 7 is also 1.\n\n``` text\nGCD(17,7) = 1\n\n17 = 7 · 2 + 3\n\n7 = 3 · 2 + 1\n\n3 = 1 · 3 + 0\n```\n\n \n\n**Another example:**\n\n``` text\nGCD(8,3) = 1\n\n8 = 3 · 2 + 2\n\n3 = 2 · 1 + 1\n\n2 = 1 · 2 + 0\n```\n\n### How does computing the GCD turn into maximally even distributed patterns?\n\nRepresent a binary sequence of k ones \\[1\\] and n − k zeros \\[0\\], where each \\[0\\] bit represents a time interval and the ones \\[1\\] indicate signal triggers.\n\nThe problem then reduces to:\n\n`Construct a binary sequence of n bits with k ones such that the ones are distributed as evenly as possible among the zeros.`\n\nA simple case is when k evenly divides n (with no remainder), in which case we should place ones every n/k bits. For example, if n = 16 and k = 4, then the solution is:\n\n`[1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0]`\n\nThis case corresponds to n and k having a common divisor of k (in this case 4).\n\nMore generally, if the greatest common divisor between n and k is g, we would expect the solution to decompose into g repetitions of a sequence of n/g bits.\n\n**This connection with greatest common divisors suggests that we could compute a maximally even rhythm using an algorithm like Euclid’s.**\n\n \n\n### Example (13, 5)\n\nLet’s consider a sequence with n = 13 and k = 5.\n\nSince 13 − 5 = 8, we start with a sequence consisting of 5 ones, followed by 8 zeros, which can be thought of as 13 one-bit sequences:\n\n\\[1 1 1 1 1 0 0 0 0 0 0 0 0\\]\n\nWe begin moving zeros by placing one zero after each one, creating five 2-bit sequences, with three remaining zeros:\n\n\\[10\\] \\[10\\] \\[10\\] \\[10\\] \\[10\\] \\[0\\] \\[0\\] \\[0\\]\n\n`13 = 5 · 2 + 3`\n\nThen we distribute the three remaining zeros similarly, placing a \\[0\\] after each \\[10\\] sequence:\n\n\\[100\\] \\[100\\] \\[100\\] \\[10\\] \\[10\\]\n\n`5 = 3 · 1 + 2`\n\nWe now have three 3-bit sequences, and a remainder of two 2-bit sequences. So we continue the same way, placing one \\[10\\] after each \\[100\\]:\n\n\\[10010\\] \\[10010\\] \\[100\\]\n\n`3 = 2 · 1 + 1`\n\nThe process stops when the remainder consists of a single sequence (here, \\[100\\]), or we run out of zeros.\n\nThe final sequence is, therefore, the concatenation of \\[10010\\], \\[10010\\], and \\[100\\]:\n\n**\\[1 0 0 1 0 1 0 0 1 0 1 0 0\\]**\n\n`2 = 1 · 2 + 0`\n\n \n\n### Example (17, 7)\n\nSuppose we have 17 pulses and want to evenly distribute 7 beats over them.\n\n**1.** We align the number of beats and silences (7 ones and 10 zeros):\n\n\\[1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\\]\n\n| 1 1 1 1 1 1 1 | 0 0 0 0 0 0 0 0 0 0 |\n|---------------|---------------------|\n\n**2.** We form 7 groups, corresponding to the division of 17 by 7; we get 7 groups of `[1 0]` and 3 remaining zeros `[000]`, which means the next step forms 3 groups until only one or zero groups remain.\n\n\\[1 0\\] \\[1 0\\] \\[1 0\\] \\[1 0\\] \\[1 0\\] \\[1 0\\] \\[1 0\\] \\[0\\] \\[0\\] \\[0\\]\n\n`17 = 7 · 2 + 3`\n\n| 1   | 1   | 1   | 1   | 1   | 1   | 1   | 0 0 0 |\n|-----|-----|-----|-----|-----|-----|-----|-------|\n| 0   | 0   | 0   | 0   | 0   | 0   | 0   |       |\n\n \n\n**3.** Again, this corresponds to dividing 7 by 3. In our case, we are left with only one group and we are done.\n\n \n\n\\[1 0 0\\] \\[1 0 0\\] \\[1 0 0\\] \\[1 0\\] \\[1 0\\] \\[1 0\\] \\[1 0\\]\n\n| 1   | 1   | 1   | 1   | 1   | 1   | 1   |\n|-----|-----|-----|-----|-----|-----|-----|\n| 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n| 0   | 0   | 0   |     |     |     |     |\n\n\\[1 0 0 1 0\\] \\[1 0 1 0 0\\] \\[1 0 0 1 0\\] \\[1 0\\]\n\n`7 = 3 · 2 + 1`\n\n| 1   | 1   | 1   | 1   |     |     |     |\n|-----|-----|-----|-----|-----|-----|-----|\n| 0   | 0   | 0   | 0   | 0   | 0   | 0   |\n| 0   | 0   | 0   |     |     |     |     |\n| 1   | 1   | 1   |     |     |     |     |\n| 0   | 0   | 0   |     |     |     |     |\n\n \n\n**4.** Finally, the rhythm is obtained by reading the grouping column by column, from left to right, step by step.\n\n**`[1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 1 0]`**\n\n`3 = 1 · 3 + 0`\n\n \n\n### Implementation in Pure Data - Euclidean sequencer\n\n```default\n(index * hits ) % steps\n↓\n[< notes]\n```\n\n\n```{mermaid}\nflowchart TB\n    A[index * hits]\n    A --> B[% steps]\n    B --> C[< notes]\n```\n\n\nwhere:\n\nindex = index of the Euclidean series (array)\n\nhits = number of notes to be played\n\nsteps = array size\n\nYoy can check this [Euclidean rhythm demo](https://dbkaplun.github.io/euclidean-rhythm/) in order to interact and see how the algorithm works.\n\n\n\n\n#### Understanding the Mathematical Formula\n\nThe formula `(index * hits) % steps < hits` provides a simple and efficient way to approximate the distribution of pulses (or beats) over a sequence of discrete steps. It works by multiplying the current position (represented by `index`) by the total number of hits (pulses) desired. This result is then taken modulo the total number of steps to ensure it wraps around properly in a cyclical pattern. Finally, the result of this modulo operation is compared to the number of hits. If the condition is true, we place a beat at that position; otherwise, we place a rest.\n\nThis method produces a rhythm by relying on modular arithmetic. The result is a mathematically regular distribution of beats that often approximates what we expect from an even rhythmic distribution. However, it does so without any recursive logic or iteration—it simply applies a consistent rule to each step in isolation. This makes the formula extremely efficient: it runs in constant time for any position, and it does not require any memory to store the pattern.\n\n#### The Bjorklund Algorithm Explained\n\nIn contrast, the Bjorklund algorithm is a more sophisticated procedure rooted in the Euclidean algorithm for computing the greatest common divisor (GCD). This algorithm begins with two values: the number of pulses (beats) and the number of rests (steps minus beats). It then recursively groups these elements in a way that maximizes the evenness of their distribution.\n\nThe method proceeds by repeatedly pairing elements—first grouping pulses with rests, then regrouping the leftovers, and so on—until the sequence cannot be subdivided further. The final pattern emerges from this recursive grouping, and it is typically rotated so that it starts with a pulse. The result is a rhythm that is maximally even, meaning that the beats are spaced as equally as possible given the constraints.\n\nThis process, while more computationally demanding and conceptually complex, produces the canonical Euclidean rhythms often cited in academic and musical literature.\n\n#### Comparing the Formula and the Algorithm\n\nThe core difference between the two approaches lies in how they arrive at the rhythmic pattern. The mathematical formula provides a direct, position-based method for determining beat placement. It does not take into account the context of previous or future beats—it treats each step in isolation. This is why it is so fast and well-suited for real-time applications, such as live audio processing in Pure Data or other creative coding environments.\n\nThe Bjorklund algorithm, on the other hand, is concerned with the global structure of the pattern. It ensures that beats are distributed with maximal evenness and follows a well-defined sequence of operations that are both recursive and stateful. This means it needs to store and manipulate arrays of data to arrive at the final rhythm. The computational complexity of this algorithm is higher, and it is not as straightforward to implement, but the results are musically and mathematically robust.\n\nOne major distinction is that the formula often produces a rotated version of the Bjorklund rhythm. That is, while the number and spacing of beats may be similar, the starting position may differ. The Bjorklund rhythm always starts with a pulse, ensuring that it adheres to a particular musical convention, while the formula does not guarantee this.\n\nAnother important distinction lies in the distribution logic. The formula uses a fixed mathematical rule to space out the beats, leading to regular but not necessarily optimal placement. The Bjorklund algorithm, however, iteratively rearranges beats and rests to achieve the best possible balance.\n\n#### A Concrete Example: (13, 5)\n\nLet’s consider the case of 13 steps with 5 beats.\n\nUsing the mathematical formula, we apply `(index * 5) % 13 < 5` for each position:\n\nPattern: 1 0 0 1 0 0 1 0 1 0 0 1 0\n\nIn contrast, the Bjorklund algorithm produces:\n\nPattern: 1 0 1 0 0 1 0 1 0 0 1 0 0\n\n\nBoth patterns contain five beats. Both distribute them fairly evenly. But the Bjorklund version achieves a more perceptually even spacing and aligns with theoretical expectations. The formula result is essentially a rotated variant.\n\nIn summary, the formula `(index * hits) % steps < hits` offers a pragmatic and computationally efficient way to generate rhythm patterns that resemble Euclidean rhythms. It is well-suited for real-time use cases and environments where simplicity and speed are more important than strict accuracy. In contrast, the Bjorklund algorithm provides a mathematically rigorous method for generating rhythms with maximal evenness. It aligns with canonical definitions and is favored in theoretical and compositional contexts.The choice between these methods depends on your priorities: use the formula for lightweight, real-time approximation, and use Bjorklund when you need precision and adherence to the canonical Euclidean model.\n\n\n## Cellular Automata\n\nA cellular automaton is a mathematical and computational model for a dynamic system that evolves in discrete steps. It is suitable for modeling natural systems that can be described as a massive collection of simple objects interacting locally with each other.\n\nA cellular automaton is a collection of \"colored\" cells on a grid of specified shape that evolves through a series of discrete time steps according to a set of rules based on the states of neighboring cells. The rules are then applied iteratively over as many time steps as desired.\n\nCellular automata come in a variety of forms and types. One of the most fundamental properties of a cellular automaton is the type of grid on which it is computed. The simplest such grid is a `one-dimensional` line. In two dimensions, square, triangular, and hexagonal grids can be considered.\n\n![Fig. Cellular Automaton](/assets/images/sequencers/cellular-automaton-rule30-1.png)\n\nOne must also specify the number of colors (or distinct states) *k* that a cellular automaton can assume. This number is typically an integer, with k=2 (binary, `[1]` or `[0]`) being the simplest choice. For a binary automaton, color 0 is commonly referred to as \"white\" and color 1 as \"black\". However, cellular automata with a continuous range of possible values can also be considered.\n\nIn addition to the grid on which a cellular automaton resides and the colors its cells can assume, one must also specify the `neighborhood` over which the cells influence each other.\n\n### One-Dimensional Cellular Automata (1DCA)\n\nThe simplest option is `\"nearest neighbors\"`, where only the cells directly adjacent to a given cell can influence it at each time step. Two common neighborhoods in the case of a two-dimensional cellular automaton on a square grid are the so-called Moore neighborhood (a square neighborhood) and the von Neumann neighborhood (a diamond-shaped neighborhood).\n\nCellular automata are considered as a vector. Each component of the vector is called a cell. Each cell is assumed to take only two states:\n\n-   \\[0\\] (white)\n-   \\[1\\] (black)\n\nThis type of automaton is known as an elementary one-dimensional cellular automaton (1DCA). A dynamic process is performed, starting from an initial configuration C(0) of each of the cells (stage 0), and at each new stage, the state of each cell is calculated based on the state of the neighboring cells and the cell itself in the previous stage.\n\n### The Case of Rule 30\n\nRule 30 is a binary one-dimensional cellular automaton introduced by [Stephen Wolfram](https://en.wikipedia.org/wiki/Stephen_Wolfram) in 1983. It considers an infinite one-dimensional array of cellular automaton cells with only two states, with each cell in some initial state.\n\nAt discrete time intervals, each cell changes state spontaneously based on its current state and the state of its two neighbors.\n\nWhat it consists of:\n\n1.  Each cell can be in one of two states: alive or dead.\n\n2.  The next generation of a cell is determined by the current state of the cell and the state of its two neighboring cells.\n\n3.  There are 8 possible configurations of neighboring states (3\\^2), and for each, Rule 30 defines whether the cell lives or dies in the next generation.\n\nFor Rule 30, the set of rules that governs the automaton's next state is:\n\n| Configuration | Next State | Binary Code |\n|---------------|------------|-------------|\n| 000           | Dead       | 000         |\n| 001           | Alive      | 011         |\n| 010           | Dead       | 000         |\n| 011           | Alive      | 011         |\n| 100           | Alive      | 011         |\n| 101           | Dead       | 000         |\n| 110           | Alive      | 011         |\n| 111           | Dead       | 000         |\n\nIn the following diagram, the top row shows the state of the central cell (cell *i*) and its two neighboring cells at a given stage, and the bottom row shows the state of the central cell in the next stage.\n\nFor example, in the first case of the figure:\n\n-   if the state of a cell at a given stage is `[1]` (black) and\n-   its two neighbors at that stage are also `[1]` (black),\n-   then the cell's state in the next stage will be `[0]` (white).\n\n![Rule 30](https://mathworld.wolfram.com/images/eps-svg/ElementaryCARule030_700.svg) [Source](https://mathworld.wolfram.com/CellularAutomaton.html)\n\nIt is called Rule 30 because in binary, 00011110<sub>2</sub> = 30.\n\nLet's break down the procedure for determining the next state in the 8 combinations:\n\n**Input configurations:** Consider the 8 possible input combinations of the three cells (a central cell and its left and right neighbors). Since each cell can be in one of two possible states (0 or 1), the combinations are 000, 001, 010, 011, 100, 101, 110, and 111.\n\n**Binary representation of the rule:** Rule 30 is represented by the number 30 in binary, which is 00011110. This binary representation determines the rules for the next state of the central cell for each of the 8 possible combinations.\n\n**Bit correspondence:** The 8 bits of the binary representation (00011110) correspond to the 8 input combinations in order. From right to left, the bits represent the next state of the central cell for each input combination.\n\nFor example, the least significant bit of 00011110 (the rightmost bit) is 0. This means that when the input combination is 000, the next state of the central cell will be 0.\n\n**Next state determination:** For each input combination (e.g., 000, 001, 010, 011, 100, 101, 110, 111), the corresponding bit in the binary representation of Rule 30 \\[00011110\\] indicates the next state of the central cell.\n\n| Input Configuration | Next State |\n|---------------------|------------|\n| 000                 | 0          |\n| 001                 | 1          |\n| 010                 | 1          |\n| 011                 | 1          |\n| 100                 | 1          |\n| 101                 | 0          |\n| 110                 | 0          |\n| 111                 | 0          |\n\nFor example, if the input combination is 000 and the corresponding bit in Rule 30 is 0, then the next state of the central cell will be 0.\n\nTherefore, the rules are not arbitrary but are determined by the binary representation of Rule 30, which specifies the next state of the central cell for each input combination of its neighbors.\n\n### Rule 30 Implementation in Python\n\n``` python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef rule30(cells):\n    \"\"\"Applies Rule 30 to the input cells.\"\"\"\n    new_cells = np.zeros_like(cells)\n    extended_cells = np.concatenate(([cells[-1]], cells, [cells[0]]))  # Apply periodic boundary conditions\n    for i in range(1, len(extended_cells) - 1):\n        neighborhood = extended_cells[i-1:i+2]\n        if np.array_equal(neighborhood, [1, 1, 1]) or np.array_equal(neighborhood, [1, 1, 0]) or \\\n           np.array_equal(neighborhood, [1, 0, 1]) or np.array_equal(neighborhood, [0, 0, 0]):\n            new_cells[i-1] = 0\n        else:\n            new_cells[i-1] = 1\n    return new_cells\n\ndef main():\n    # Initialize the cells\n    cells = np.zeros(100)\n    cells[50] = 1  # Start with one cell in the middle\n\n    # Apply Rule 30 for 100 steps\n    history = [cells]\n    for i in range(100):\n        cells = rule30(cells)\n        history.append(cells)\n\n    # Display the history as an image\n    plt.imshow(history, cmap='binary')\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis Python script uses the numpy and matplotlib libraries to simulate and visualize the evolution of a cellular automaton using Rule 30.\n\nThe `rule30` function is the core of this script. It takes a one-dimensional array of cells as input, where each cell is either 0 or 1. The function first creates a new array `new_cells` with the same shape as the input, filled with zeros. It then extends the input array at both ends to apply periodic boundary conditions, meaning that the first cell is considered a neighbor of the last cell and vice versa.\n\nNext, the function iterates over each cell in the extended array (excluding the added boundary cells). For each cell, it considers the cell and its two neighbors as a neighborhood. If the neighborhood matches one of four specific patterns (\\[1, 1, 1\\], \\[1, 1, 0\\], \\[1, 0, 1\\], or \\[0, 0, 0\\]), the corresponding cell in `new_cells` is set to 0. Otherwise, it is set to 1. This is the implementation of Rule 30. Finally, the function returns the new array of cells.\n\nThe main function initializes a one-dimensional array of 100 cells, all set to 0 except the middle cell, which is set to 1. It then applies the `rule30` function to this array 100 times, storing each resulting array in a list called `history`. This list is then visualized as a binary image using matplotlib's `imshow` function, where each row corresponds to one step in the cellular automaton's evolution.\n\nThe script is designed to run as a standalone program. The line `if __name__ == \"__main__\":` ensures that the main function is called only when the script is run directly, not when imported as a module.\n\n### Two-Dimensional Cellular Automata (2DCA)\n\nTwo-dimensional cellular automata are an extension of one-dimensional cellular automata, where cells not only have neighbors to the left and right, but also above and below. This allows modeling of more complex and structurally rich systems, such as two-dimensional phenomena like wave propagation, growth patterns in biology, fire spread, fluid simulation, among others.\n\nTwo-dimensional cellular automata (2DCA) are computational models that simulate dynamic systems on a two-dimensional grid.\n\nThey consist of:\n\n1.  *Cells*: Each cell in the grid can have a finite state, such as alive or dead, and can change state according to the automaton’s rules.\n\n2.  *Neighborhood*: Each cell has a neighborhood, which is a set of adjacent cells that influence its state. The neighborhood can be rectangular, hexagonal, circular, or of any other shape.\n\n3.  *Transition rule*: The transition rule defines how the state of a cell changes based on its current state and the state of the cells in its neighborhood. The rule can be deterministic or probabilistic.\n\n4.  *Evolution*: The cellular automaton evolves through iterations. In each iteration, the state of each cell is updated according to the transition rule.\n\n\n### Case Study: Conway's Game of Life\n\n![Game of life](https://images.squarespace-cdn.com/content/v1/59413d96e6f2e1c6837c7ecd/1592233649594-7UQA8NZSNXMZWX86FIWN/JB_Game_of_Life.gif?format=2500w)\n\n[Source](https://www.artnome.com/news/2020/7/12/the-game-of-life-emergence-in-generative-art)\n\nConway's Game of Life, also known simply as the Game of Life, is a cellular automaton devised by British mathematician John Horton Conway in 1970. It is the best-known example of a cellular automaton.\n\nThe \"game\" is actually a zero-player game, meaning its evolution is determined by its initial state, requiring no further input from human players. One interacts with the Game of Life by creating an initial configuration and observing how it evolves.\n\n[View Original Article - MATHEMATICAL GAMES - The fantastic combinations of John Conway's new solitaire game life (Martin Gardner)](https://ballyalley.com/articles_and_news/LIFE_Article_%28Scientific_American%29%28October_1970%29.pdf)\n\n`GOL` (Game of Life) and `CGOL` (Conway's Game of Life) are commonly used acronyms.\n\n[![Game of Life](https://img.youtube.com/vi/xP5-iIeKXE8/0.jpg)](https://www.youtube.com/watch?v=xP5-iIeKXE8)\n\n[Source](https://www.youtube.com/watch?v=xP5-iIeKXE8)\n\n#### Rules\n\nThe universe of the Game of Life is an infinite two-dimensional orthogonal grid of square cells, each of which (at any given time) is in one of two possible states, `alive` (alternatively \"on\") or `dead` (alternatively \"off\"). At each time step, the following transitions occur:\n\n**The four rules of Conway's Game of Life:**\n\n**1. Overpopulation**: Any live cell with more than three live neighbors dies due to overpopulation.\n\n**2. Underpopulation**: Any live cell with fewer than two live neighbors dies due to underpopulation.\n\n**3. Stability**: Any live cell with two or three live neighbors survives to the next generation.\n\n**4. Reproduction**: Any dead cell with exactly three live neighbors becomes a live cell.\n\n \n\nWe can also summarize the rules in a table:\n\n| Rule | Description | Current State | Live Neighbors | Next State |\n|--------------|-----------------|--------------|--------------|--------------|\n| Overpopulation | Death by overcrowding | Alive | More than 3 | Dead |\n| Underpopulation | Death by isolation | Alive | Fewer than 2 | Dead |\n| Stability | Survival | Alive | 2 or 3 | Alive |\n| Reproduction | Birth | Dead | 3 | Alive |\n\n \n\nOr summarized as:\n\n0 → 3 live neighbors → 1 1 → \\< 2 or \\> 3 live neighbors → 0\n\nWhere 0 represents a dead cell and 1 a live cell.\n\n \n\n![Game of life rules](https://the-mvm.github.io/assets/img/posts/20210210/GameOfLife.gif)\n\n[Source](https://the-mvm.github.io/conways-game-of-life.html)\n\n \n\n![Game of life rules](https://d2r55xnwy6nx47.cloudfront.net/uploads/2024/01/TheRulesOfLifebyMerrillSherman_560-Desktop.svg)\n\n[Source](https://www.quantamagazine.org/maths-game-of-life-reveals-long-sought-repeating-patterns-20240118/)\n\nThe initial pattern constitutes the system's 'seed'. The first generation is created by applying the above rules simultaneously to each cell in the seed; births and deaths occur simultaneously, and the discrete moment in which this occurs is sometimes called a step. (In other words, each generation is a pure function of the previous one.) The rules continue to be applied repeatedly to create more generations.\n\n### Origins\n\nConway was interested in a problem presented in the 1940s by renowned mathematician John von Neumann, who was trying to find a hypothetical machine that could build copies of itself and succeeded when he found a mathematical model for such a machine with very complicated rules on a rectangular grid. The Game of Life emerged as Conway’s successful attempt to simplify von Neumann’s ideas.\n\nThe game made its first public appearance in the October 1970 issue of Scientific American, in Martin Gardner’s \"Mathematical Games\" column, under the title \"The fantastic combinations of John Conway’s new solitaire game 'Life'\".\n\nSince its publication, Conway’s Game of Life has attracted significant interest due to the surprising ways patterns can evolve.\n\nLife is an example of emergence and self-organization. It is of interest to physicists, biologists, economists, mathematicians, philosophers, generative scientists, and others, as it shows how complex patterns can emerge from the implementation of very simple rules. The game can also serve as a didactic analogy, used to convey the somewhat counterintuitive notion that \"design\" and \"organization\" can spontaneously arise in the absence of a designer.\n\nConway carefully selected the rules, after considerable experimentation, to meet three criteria:\n\n1.  There should be no initial pattern for which a simple proof exists that the population can grow without limit.\n\n2.  There must be initial patterns that appear to grow indefinitely.\n\n3.  There should be simple initial patterns that evolve and change for a considerable period before ending in one of the following ways:\n\n    -   dying out completely (due to overcrowding or becoming too sparse); or\n    -   settling into a stable configuration that remains unchanged thereafter, or entering an oscillating phase in which they repeat a cycle endlessly of two or more periods.\n\n### Patterns\n\nMany different types of patterns occur in the Game of Life, including static patterns (\"still lifes\"), repeating patterns (\"oscillators\" – a superset of still lifes), and patterns that move across the board (\"spaceships\"). Common examples of these three classes are shown below, with live cells in black and dead cells in white.\n\n![Gosper glider gun](https://blog.xojo.com/wp-content/uploads/2022/05/CleanShot-2022-05-02-at-14.25.12@2x.png)\n\nUsing the provided rules, you can investigate the evolution of simple patterns:\n\n![3 cells](https://pi.math.cornell.edu/~lipa/mec/lifep.png)\n\n![4 cells](https://pi.math.cornell.edu/~lipa/mec/4life2.png)\n\n[Source](https://pi.math.cornell.edu/~lipa/mec/lesson6.html)\n\nPatterns that evolve for long periods before stabilizing are called `Methuselahs`, the first of which discovered was the `R-pentomino`.\n\n![R-pendomino](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Game_of_life_fpento.svg/164px-Game_of_life_fpento.svg.png)\n\n`Diehard` is a pattern that eventually disappears, rather than stabilizing, after 130 generations, which is believed to be the maximum for initial patterns with seven or fewer cells.\n\n![Diehard](https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Game_of_life_diehard.svg/324px-Game_of_life_diehard.svg.png)\n\n`Acorn` takes 5,206 generations to produce 633 cells, including 13 escaping gliders.\n\n![Acorn](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Game_of_life_acorn.svg/292px-Game_of_life_acorn.svg.png)\n\nConway originally conjectured that no pattern could grow indefinitely; that is, for any initial configuration with a finite number of live cells, the population could not grow beyond some finite upper bound. The `Gosper glider gun` pattern produces its first glider in the 15th generation, and another every 30 generations thereafter.\n\n![Gosper's glider gun](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Game_of_life_glider_gun.svg/1000px-Game_of_life_glider_gun.svg.png)\n\n![Gosper glider gun](https://upload.wikimedia.org/wikipedia/commons/e/e5/Gospers_glider_gun.gif)\n\nFor many years, this pattern was the smallest known. In 2015, a gun called `Simkin glider gun` was discovered, which emits a glider every 120 generations, and has fewer live cells but is spread across a larger bounding box at its ends.\n\n![Simkin glider gun](https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Game_of_life_Simkin_glider_gun.svg/1000px-Game_of_life_Simkin_glider_gun.svg.png)\n\n[Source](https://medium.com/@swarajkalbande123/conways-game-of-life-life-on-computer-b7edfc85d21a) ![Glider Patterns](https://miro.medium.com/v2/resize:fit:1024/format:webp/0*7nf3iKnIaVET4mnr)\n\n[Source](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life)\n\n### Python Implementation of Game of Life\n\n``` python\nimport time\nimport pygame\nimport numpy as np\n\nCOLOR_BG = (10, 10, 10,)  # Color de fondo\nCOLOR_GRID = (40, 40, 40)  # Color de la cuadrícula\nCOLOR_DIE_NEXT = (170, 170, 170)  # Color de las células que mueren en la siguiente generación\nCOLOR_ALIVE_NEXT = (255, 255, 255)  # Color de las células que siguen vivas en la siguiente generación\n\npygame.init()\npygame.display.set_caption(\"conway's game of life\")  # Título de la ventana del juego\n\n# Función para actualizar la pantalla con las células\ndef update(screen, cells, size, with_progress=False):\n    updated_cells = np.zeros((cells.shape[0], cells.shape[1]))  # Matriz para almacenar las células actualizadas\n\n    for row, col in np.ndindex(cells.shape):\n        alive = np.sum(cells[row-1:row+2, col-1:col+2]) - cells[row, col]  # Cálculo de células vecinas vivas\n        color = COLOR_BG if cells[row, col] == 0 else COLOR_ALIVE_NEXT  # Color de la célula actual\n\n        if cells[row, col] == 1:  # Si la célula actual está viva\n            if alive < 2 or alive > 3:  # Si tiene menos de 2 o más de 3 vecinos vivos, muere\n                if with_progress:\n                    color = COLOR_DIE_NEXT\n            elif 2 <= alive <= 3:  # Si tiene 2 o 3 vecinos vivos, sigue viva\n                updated_cells[row, col] = 1\n                if with_progress:\n                    color = COLOR_ALIVE_NEXT\n        else:  # Si la célula actual está muerta\n            if alive == 3:  # Si tiene exactamente 3 vecinos vivos, revive\n                updated_cells[row, col] = 1\n                if with_progress:\n                    color = COLOR_ALIVE_NEXT\n\n        pygame.draw.rect(screen, color, (col * size, row * size, size - 1, size - 1))  # Dibuja la célula en la pantalla\n\n    return updated_cells  # Devuelve las células actualizadas\n\n# Función principal del programa\ndef main():\n    pygame.init()\n    screen = pygame.display.set_mode((800, 600))  # Crea la ventana del juego\n\n    cells = np.zeros((60, 80))  # Crea una matriz de células muertas\n    screen.fill(COLOR_GRID)  # Rellena la pantalla con el color de la cuadrícula\n    update(screen, cells, 10)  # Actualiza la pantalla con las células\n\n    pygame.display.flip()\n    pygame.display.update()\n\n    running = False  # Variable para controlar si el juego está en ejecución\n\n    while True:\n        for Q in pygame.event.get():\n            if Q.type == pygame.QUIT:  # Si se cierra la ventana, termina el programa\n                pygame.quit()\n                return\n            elif Q.type == pygame.KEYDOWN:\n                if Q.key == pygame.K_SPACE:  # Si se presiona la tecla espacio, se inicia o pausa el juego\n                    running = not running\n                    update(screen, cells, 10)\n                    pygame.display.update()\n            if pygame.mouse.get_pressed()[0]:  # Si se presiona el botón izquierdo del ratón\n                pos = pygame.mouse.get_pos()  # Obtiene la posición del ratón\n                cells[pos[1] // 10, pos[0] // 10] = 1  # Marca la célula correspondiente como viva\n                update(screen, cells, 10)\n                pygame.display.update()\n\n        screen.fill(COLOR_GRID)  # Rellena la pantalla con el color de la cuadrícula\n\n        if running:  # Si el juego está en ejecución\n            cells = update(screen, cells, 10, with_progress=True)  # Actualiza las células con progreso\n            pygame.display.update()\n\n        time.sleep(0.001)  # Espera un breve tiempo para controlar la velocidad del juego\n\nif __name__ == \"__main__\":\n    main()\n```\n\n------------------------------------------------------------------------\n\nThis Python script implements Conway’s Game of Life, a cellular automaton devised by British mathematician John Horton Conway. It is a zero-player game, meaning its evolution is determined entirely by its initial state, with no further input required.\n\nThe script begins by importing the necessary modules: `time`, `pygame` for the graphical interface, and `numpy` to handle the game grid as a 2D matrix. It then defines color constants used for visualizing the game.\n\nThe `pygame.init()` function is called to initialize all imported Pygame modules. The window title is set to “Conway’s Game of Life” using `pygame.display.set_caption()`.\n\nThe `update()` function updates the game state and redraws the grid. It takes four arguments: `screen` (the Pygame surface to draw on), `cells` (the current game state as a 2D `numpy` array), `size` (the pixel size of each cell), and `with_progress` (a boolean indicating whether to display cells that will change in the next generation).\n\nThe function creates a new 2D matrix `updated_cells` filled with zeros, matching the shape of `cells`. It then iterates over each cell, calculates the number of live neighbors, and applies the game rules to determine whether the cell will be alive in the next generation. The function draws each cell on the screen using the appropriate color and returns `updated_cells`.\n\nThe `main()` function initializes Pygame, creates the game window, and initializes the game state as a 2D `numpy` array of zeros (representing dead cells). It then enters the main loop, which handles Pygame events (such as closing the window or key presses), updates the game state if it is running, and redraws the grid. The game can be started or paused by pressing the spacebar, and cells can be toggled manually by clicking on them.\n\nFinally, the script calls `main()` to launch the game. Press the spacebar to begin.\n\n### Further Reading\n\n-   [The Game Of Life – Emergence In Generative Art (2020)](https://www.artnome.com/news/2020/7/12/the-game-of-life-emergence-in-generative-art)\n-   [Conway’s Game of Life – Life on Computer by Swaraj Kalbande](https://medium.com/@swarajkalbande123/conways-game-of-life-life-on-computer-b7edfc85d21a)\n-   [Wikipedia – Conway's Game of Life](https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life)\n\n### Interactive Websites\n\n-   [John Conway’s Game of Life – An Introduction to Cellular Automata](https://beltoforion.de/en/game_of_life/)\n-   [conwaylife.com](https://conwaylife.com/)\n-   [Cellular Automata Megathread](https://nga.178.com/read.php?tid=21761699&rand=998)\n\n------------------------------------------------------------------------\n\n",
    "supporting": [
      "sequencers_files"
    ],
    "filters": [],
    "includes": {}
  }
}